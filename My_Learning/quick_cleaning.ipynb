{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a281456-135d-4520-937a-682d02b274d9",
   "metadata": {},
   "source": [
    "## Quick Checks on Data\n",
    "\n",
    "The snippets below doesn't reflect any real scenario. Its intent is only serving as a quick consult. They'll be constantly updated as new ideas come up. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5061988-895e-4a56-89c2-1e2c17d87306",
   "metadata": {},
   "source": [
    "### 0 - Loading the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "223c7ff8-64ed-4d89-8254-ccd172481b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing main libraries\n",
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa3b8b17-8216-45b2-b67e-eb6b383c326e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TransactionID CustomerName Product  Price  Quantity TransactionDate\n",
      "0            101    Jane Rust  Laptop   1200       1.0      2024-12-01\n",
      "1            102   june young   Phone    800       2.0      2024/12/01\n",
      "2            103    Jane Rust  Laptop   1200       NaN      01-12-2024\n",
      "3            104          NaN  Tablet   -300       1.0             NaN\n",
      "4            105   JUNE YOUNG   Phone    850       1.0      2024-12-01\n"
     ]
    }
   ],
   "source": [
    "#setting variables for data frame\n",
    "quick_dataset = pd.read_csv('data/sample_dataset.csv')\n",
    "\n",
    "quick_df = pd.DataFrame(quick_dataset)\n",
    "\n",
    "print(quick_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a3a13-93df-4ac8-aec9-e9715fa98249",
   "metadata": {},
   "source": [
    "As a good practice, index should start on number 1, instead of 0 and the moment to have it fixed is before starting the cleaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a48c6d2-6bae-4638-a6b5-d7e39e9c2835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the index to start at 1\n",
    "quick_df.index += 1\n",
    "\n",
    "# And then overwriting the original file\n",
    "quick_df.to_csv(\"data/sample_dataset.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4edacc69-6ef9-48c0-b8d9-bc5518ae67d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 1 to 5\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   TransactionID    5 non-null      int64  \n",
      " 1   CustomerName     4 non-null      object \n",
      " 2   Product          5 non-null      object \n",
      " 3   Price            5 non-null      int64  \n",
      " 4   Quantity         4 non-null      float64\n",
      " 5   TransactionDate  4 non-null      object \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 372.0+ bytes\n",
      "   TransactionID CustomerName Product  Price  Quantity TransactionDate\n",
      "1            101    Jane Rust  Laptop   1200       1.0      2024-12-01\n",
      "2            102   june young   Phone    800       2.0      2024/12/01\n",
      "3            103    Jane Rust  Laptop   1200       NaN      01-12-2024\n",
      "4            104          NaN  Tablet   -300       1.0             NaN\n",
      "5            105   JUNE YOUNG   Phone    850       1.0      2024-12-01\n"
     ]
    }
   ],
   "source": [
    "# some basic information on the dataframe\n",
    "quick_df.info()\n",
    "print(quick_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0345c2e-3277-4f80-886c-557b58073637",
   "metadata": {},
   "source": [
    "So it's possible to see some interesting findings in a glance, for instance: \n",
    "- this ia a store data,\n",
    "- there are six columns,\n",
    "- some cleaning will be necessary, such as:  NaN, negative values where it shouldn't be, duplicate, different date formats, and so on. \n",
    "- TransactionData data type is an object and it should be datetime type. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10910313-e602-42c6-8f75-cf8644ce32a8",
   "metadata": {},
   "source": [
    "### 1 - Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20358a44-b8db-4992-a119-e0a69cb96525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransactionID      0\n",
      "CustomerName       1\n",
      "Product            0\n",
      "Price              0\n",
      "Quantity           1\n",
      "TransactionDate    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking and summing missing values\n",
    "missing_values = quick_df.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a474ca-7f76-40bc-bd3c-4732c425522e",
   "metadata": {},
   "source": [
    "### 2 - Identifying Incorrect Data Types \n",
    "\n",
    "We've already noticed that TransactionDate column has an incorrect data type. Let's try to figure out whether there are others. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d90b71ce-4a4b-4371-af62-dc76e95a6354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types:\n",
      " TransactionID        int64\n",
      "CustomerName        object\n",
      "Product             object\n",
      "Price                int64\n",
      "Quantity           float64\n",
      "TransactionDate     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Types:\\n\", quick_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89986ec4-e131-41fd-b284-cb5e2955dbd2",
   "metadata": {},
   "source": [
    "### 3 - Consistent Format for Dates\n",
    "\n",
    "On TransactionDate column the date formats are not consistent. We need to fix it up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b224797e-ebfd-406b-9c6c-6f979cee0f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   2024-12-01\n",
      "2          NaT\n",
      "3          NaT\n",
      "4          NaT\n",
      "5   2024-12-01\n",
      "Name: TransactionDate, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# as this is a quick check, let's create an extra dataframe, so we can handle this issue properly later on\n",
    "NaT_qdf = quick_df.copy()\n",
    "NaT_qdf[\"TransactionDate\"] = pd.to_datetime(NaT_qdf[\"TransactionDate\"], errors=\"coerce\")\n",
    "print(NaT_qdf[\"TransactionDate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a01c33-2aea-46f7-ad68-af8ab3be2b50",
   "metadata": {},
   "source": [
    "*NaT* stands for \"Not a Time\", so it means that the values on the rows 2, 3 and 4, weren't recognized as any date format. Later on will address this properly, as above mentioned. For the time being, the TransactionDate column won't be touched. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f949708-a20a-40ad-b601-6583a9f42839",
   "metadata": {},
   "source": [
    "### 4 - Outliers \n",
    "\n",
    "We know that domain knowledge is necessary to search for outliers, but it's pretty straight forward applicable to this case, as there is no negative prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "02678a4d-f4df-4d08-b381-e4022068decc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers:\n",
      "    TransactionID CustomerName Product  Price  Quantity TransactionDate\n",
      "3            104          NaN  Tablet   -300       1.0             NaT\n"
     ]
    }
   ],
   "source": [
    "outliers = quick_df[quick_df[\"Price\"] < 0]\n",
    "print(\"Outliers:\\n\", outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af6cb90-240e-4716-915f-6e680439675a",
   "metadata": {},
   "source": [
    "### 5 - Finding Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f0fce6-73cd-4a7e-8c1f-bccb21130265",
   "metadata": {},
   "source": [
    "Certainly, in a first view, if we run an automatic check on all the columns, TransactionDate will show duplicates, which doesn't make sense as some records of sales could have happened in the same day. That said, this column will be excluded from this check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73aadfbf-4e0e-4ccc-beda-1ca87bc7c003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Records\n",
      "    TransactionID CustomerName Product  Price  Quantity TransactionDate\n",
      "0            101    Jane Rust  Laptop   1200       1.0      2024-12-01\n",
      "2            103    Jane Rust  Laptop   1200       NaN      01-12-2024\n"
     ]
    }
   ],
   "source": [
    "duplicates = quick_df.duplicated(subset=[\"CustomerName\", \"Product\"], keep=False)\n",
    "print(\"Duplicate Records\\n\", quick_df[duplicates])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541726cf-43ab-4928-aa2a-65dc1710fdfd",
   "metadata": {},
   "source": [
    "Jane Rust appears twice in this dataset, possibly so do June Yung, but this customer name is typed in capital letters. Next topic this issue will be addressed.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cc97b9-6cb0-432e-8d64-9e6a9fd4169b",
   "metadata": {},
   "source": [
    "### 6 - Text Data Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd41e85b-0dcb-4ed6-9540-cb683e10f53c",
   "metadata": {},
   "source": [
    "In standardization, it is possible to remove extra spaces and ensuring proper capitalization, as it will be right now done on CustomerName column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6e874509-f797-49a8-a4e5-bd5429d1c883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     Jane Rust\n",
      "2    June Young\n",
      "3     Jane Rust\n",
      "4           NaN\n",
      "5    June Young\n",
      "Name: CustomerName, dtype: object\n"
     ]
    }
   ],
   "source": [
    "quick_df[\"CustomerName\"] = quick_df[\"CustomerName\"].str.strip().str.title()\n",
    "print(quick_df[\"CustomerName\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84578034-f64e-4b5a-856d-9e1912dec782",
   "metadata": {},
   "source": [
    "##### *** Running again the previous code for duplicate verification purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6d4c625e-8677-4089-8830-2ee48957a70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Records\n",
      "    TransactionID CustomerName Product  Price  Quantity TransactionDate\n",
      "1            101    Jane Rust  Laptop   1200       1.0      2024-12-01\n",
      "2            102   June Young   Phone    800       2.0      2024/12/01\n",
      "3            103    Jane Rust  Laptop   1200       NaN      01-12-2024\n",
      "5            105   June Young   Phone    850       1.0      2024-12-01\n"
     ]
    }
   ],
   "source": [
    "duplicates = quick_df.duplicated(subset=[\"CustomerName\", \"Product\"], keep=False)\n",
    "print(\"Duplicate Records\\n\", quick_df[duplicates])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58b64c6-def7-4c4e-80f2-5f0bcbd9cdba",
   "metadata": {},
   "source": [
    "Jane Rust on TransactionID 101 and 103 seems to be a duplicate, as they have the same day, product and price. On the other side, June Yung doesn't, as the price aren't the same, neither Quantity values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5986ce46-a3c8-41d3-8e4a-72b1a865be02",
   "metadata": {},
   "source": [
    "### 7 - Validate Data Ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d54d801-d4cf-468c-a375-c5433609f751",
   "metadata": {},
   "source": [
    "Prices need to lie within an expected range, or at least no negative price. Once the stakeholders are consulted about the highest product price, we can stablish a maximum price, and obviously 0 will be the minimum. A maximum amount for our purpose would be 5000, so anything outside of a range of 0 and 5000 will be flagged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "397b86f5-3fba-4a96-a141-0dcc8e8b466a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Prices:\n",
      "    TransactionID CustomerName Product  Price  Quantity TransactionDate\n",
      "4            104          NaN  Tablet   -300       1.0             NaN\n"
     ]
    }
   ],
   "source": [
    "invalid_prices = quick_df[~quick_df[\"Price\"].between(0, 5000)]\n",
    "print(\"Invalid Prices:\\n\", invalid_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3367aa-7b13-4d48-ac40-bf1cf4241c87",
   "metadata": {},
   "source": [
    "So, on row with TransactionID 104, there is a negative price. Probably a typo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf247ab-09ad-4353-b339-8cf47a4c7de0",
   "metadata": {},
   "source": [
    "### 8 - Unique Values per Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da66c6b4-ce50-483f-a3de-aff2baa4902c",
   "metadata": {},
   "source": [
    "How many times each product appears? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6df43bf1-019d-4314-b260-38e9f46d3a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Products:/n Product\n",
      "Laptop    2\n",
      "Phone     2\n",
      "Tablet    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# using \"value-counts()\" will provide use the answer, spotting the typos and/or anomalies in categorical data\n",
    "unique_products =quick_df[\"Product\"].value_counts()\n",
    "print(\"Unique Products:/n\", unique_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dfcabf-7f81-4e9f-b3ee-83bee16e8aef",
   "metadata": {},
   "source": [
    "### 9 - Insconsistent Formatting Across Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6a13ce19-8684-47b2-88b7-4764b6038f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inconsistent Formatting in Names:\n",
      " Empty DataFrame\n",
      "Columns: [TransactionID, CustomerName, Product, Price, Quantity, TransactionDate]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "inconsistent_words = quick_df[\"CustomerName\"].str.contains(r\"A-Z]{2,}\", na=False)\n",
    "print(\"Inconsistent Formatting in Names:\\n\", quick_df[inconsistent_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826a0f46-b8a4-4bcf-b1a5-b73a4138ac2b",
   "metadata": {},
   "source": [
    "Remembering that what could be formatted was already done, as in 'CustomerName' column. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03024d9f-4136-429a-94f2-3fb79d00b251",
   "metadata": {},
   "source": [
    "### 10 - Rows with Multiple Issues "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b19483-ba41-48f3-8ba9-f94073c7a121",
   "metadata": {},
   "source": [
    "With a just a shot is possible to check many rows with multiple issues, like missing values, negative prices, invalid dates, so the focus should be directed to them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "93cf1f68-37c6-4acb-975d-fe19e9c5c273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows that need attention:\n",
      "    TransactionID CustomerName Product  Price  Quantity TransactionDate\n",
      "4            104          NaN  Tablet   -300       1.0             NaN\n"
     ]
    }
   ],
   "source": [
    "issues = quick_df.isnull().sum(axis=1) + (quick_df[\"Price\"] < 0) + (~quick_df[\"TransactionDate\"].notnull())\n",
    "flagged_rows = quick_df[issues > 1]\n",
    "print(\"Rows that need attention:\\n\", flagged_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10afcddb-642e-4983-9526-13e5ff7cf7f0",
   "metadata": {},
   "source": [
    "This cell doesn't have values for CustomerName and TransactionDate, also the price pointed out on it is negative, so there is no fix at this stage. \n",
    "\n",
    "Once the quick check was done, the cleaning will be complete in the next topic. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df467f4b-6f1a-4975-a638-5c5dc705ca60",
   "metadata": {},
   "source": [
    "### 11 - Addressing Issues Properly\n",
    "\n",
    "As the code snippets above are only meant for a quick check, this last topics aims to address some issues properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "adcff7fd-5e56-46fc-8138-f8440e218dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   2024-12-01\n",
      "2   2024-12-01\n",
      "3   2024-12-01\n",
      "4          NaT\n",
      "5   2024-12-01\n",
      "Name: TransactionDate, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# the function below will sort out the multiple format dates issues\n",
    "from datetime import datetime\n",
    "\n",
    "def parse_date(date_str):\n",
    "    # Handle missing or invalid values\n",
    "    if date_str in [\"nan\", \"None\", \"\"]:\n",
    "        return pd.NaT\n",
    "    \n",
    "    # First check for the specific format \"DD-MM-YYYY\"\n",
    "    if len(date_str) == 10 and date_str[2] == \"-\" and date_str[5] == \"-\":\n",
    "        try:\n",
    "            return datetime.strptime(date_str, \"%d-%m-%Y\")\n",
    "        except ValueError:\n",
    "            return pd.NaT\n",
    "\n",
    "    # Attempt parsing with known formats\n",
    "    formats = [\"%Y-%m-%d\", \"%Y/%m/%d\"]\n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            return datetime.strptime(date_str, fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    # Return NaT if no format matches\n",
    "    return pd.NaT\n",
    "\n",
    "# Ensure TransactionDate is a string\n",
    "quick_df[\"TransactionDate\"] = quick_df[\"TransactionDate\"].astype(str).str.strip()\n",
    "\n",
    "# Apply the custom parsing function\n",
    "quick_df[\"TransactionDate\"] = quick_df[\"TransactionDate\"].apply(parse_date)\n",
    "\n",
    "# Verify the result\n",
    "print(quick_df[\"TransactionDate\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03fe1af-859c-4f98-b510-aab068d48613",
   "metadata": {},
   "source": [
    "The only 'NaT' value is because there isn't really any value in that cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4d084491-52bb-4f22-9096-5dc3070027d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TransactionID CustomerName Product  Price  Quantity TransactionDate\n",
      "1            101    Jane Rust  Laptop   1200       1.0      2024-12-01\n",
      "2            102   June Young   Phone    800       2.0      2024-12-01\n",
      "3            103    Jane Rust  Laptop   1200       NaN      2024-12-01\n",
      "4            104          NaN  Tablet   -300       1.0             NaT\n",
      "5            105   June Young   Phone    850       1.0      2024-12-01\n"
     ]
    }
   ],
   "source": [
    "print(quick_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
